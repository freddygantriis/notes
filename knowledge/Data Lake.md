A data lake is a centralized repository that ingests and stores large volumes of data in its original form. The data can then be processed and used as a basis for a variety of analytic needs. Due to its open, scalable architecture, a data lake can accommodate all types of data from any source, from structured (database tables, Excel sheets) to semi-structured (XML files, webpages) to unstructured (images, audio files, tweets), all without sacrificing fidelity. The data files are typically stored in staged zones—raw, cleansed, and curated—so that different types of users may use the data in its various forms to meet their needs. Data lakes provide core data consistency across a variety of applications, powering [big data analytics](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-big-data-analytics/), [machine learning](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-machine-learning-platform/), predictive analytics, and other forms of intelligent action.

source: https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-a-data-lake